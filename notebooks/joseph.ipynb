{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and perform Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset to inspect its structure\n",
    "tweet_data = pd.read_csv('../data_file/tweet_sentiments.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of the following key columns:\n",
    "\n",
    "* **tweet_text:** The actual text of the Tweet.\n",
    "* **emotion_in_tweet_is_directed_at:** The product or brand mentioned in the Tweet (e.g., iPhone, iPad, Google).\n",
    "* **is_there_an_emotion_directed_at_a_brand_or_product:** The sentiment or emotion expressed in the Tweet (e.g., Positive emotion, Negative emotion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "tweet_text                                               1\n",
      "emotion_in_tweet_is_directed_at                       5802\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n",
      "\n",
      "Sentiment Distribution:\n",
      "No emotion toward brand or product    5389\n",
      "Positive emotion                      2978\n",
      "Negative emotion                       570\n",
      "I can't tell                           156\n",
      "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values and get a summary of the dataset\n",
    "missing_values = tweet_data.isnull().sum()\n",
    "\n",
    "# Check the distribution of sentiment classes\n",
    "sentiment_distribution = tweet_data['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()\n",
    "\n",
    "# Display the missing values and sentiment distribution\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(sentiment_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains the following observations:\n",
    "\n",
    "1. There is one missing value in the `tweet_text` column and a large number (5802) in the `emotion_in_tweet_is_directed_at column`, which is not crucial for sentiment classification as our primary target is the sentiment.\n",
    "\n",
    "2. The sentiment distribution shows a significant imbalance, with:\n",
    "   * **5389** instances labeled as \"No emotion toward brand or product.\"\n",
    "   * **2978** labeled as \"Positive emotion.\"\n",
    "   * **570** labeled as \"Negative emotion.\"\n",
    "   * **156** instances labeled as \"I can't tell.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing tweet_text and drop the column 'emotion_in_tweet_is_directed_at' as it is not necessary for sentiment analysis\n",
    "cleaned_tweet_data = tweet_data.dropna(subset=['tweet_text']).drop(columns=['emotion_in_tweet_is_directed_at'])\n",
    "\n",
    "# Display the cleaned dataset for further inspection\n",
    "cleaned_tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            0\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-checking that there are no missing values\n",
    "missing_values = cleaned_tweet_data.isnull().sum()\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been successfully cleaned by removing the missing entries from the `tweet_text` column and dropping the irrelevant `emotion_in_tweet_is_directed_at` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\engig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\engig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\engig\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>wesley g iphone hr tweeting riseaustin dead ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>jessedee know fludapp awesome ipadiphone app y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>swonderlin wait ipad also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>sxsw hope year festival isnt crashy year iphon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>sxtxstate great stuff fri sxsw marissa mayer g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  wesley g iphone hr tweeting riseaustin dead ne...  \n",
       "1  jessedee know fludapp awesome ipadiphone app y...  \n",
       "2                swonderlin wait ipad also sale sxsw  \n",
       "3  sxsw hope year festival isnt crashy year iphon...  \n",
       "4  sxtxstate great stuff fri sxsw marissa mayer g...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries for text preprocessing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenization\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stop words and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply the preprocessing function to the 'tweet_text' column\n",
    "cleaned_tweet_data['cleaned_text'] = cleaned_tweet_data['tweet_text'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the preprocessed data\n",
    "cleaned_tweet_data[['tweet_text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cleaned_text` column now contains preprocessed Tweet text, which has been:\n",
    "\n",
    "* Converted to lowercase.\n",
    "* Stripped of punctuation and special characters.\n",
    "* Tokenized, with stop words removed.\n",
    "* Lemmatized to reduce words to their base form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Feature Engineering\n",
    "\n",
    "Convert the cleaned text into numerical features using Term Frequency-Inverse Document Frequency (TF-IDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9092, 5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define the TF-IDF Vectorizer with a maximum of 5000 features and stop words removed\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text data into TF-IDF features\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(cleaned_tweet_data['cleaned_text'])\n",
    "\n",
    "# Display the shape of the resulting TF-IDF matrix\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting matrix contains 9,092 rows (one for each Tweet) and 5,000 TF-IDF features (words or terms) based on the cleaned text data. Each cell in the matrix represents the TF-IDF score for a specific word in a specific Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aapl  aaron  aarpbulletin   ab  abacus  abba  abc  ability  able  abnormal\n",
      "0   0.0    0.0           0.0  0.0     0.0   0.0  0.0      0.0   0.0       0.0\n",
      "1   0.0    0.0           0.0  0.0     0.0   0.0  0.0      0.0   0.0       0.0\n",
      "2   0.0    0.0           0.0  0.0     0.0   0.0  0.0      0.0   0.0       0.0\n",
      "3   0.0    0.0           0.0  0.0     0.0   0.0  0.0      0.0   0.0       0.0\n",
      "4   0.0    0.0           0.0  0.0     0.0   0.0  0.0      0.0   0.0       0.0\n"
     ]
    }
   ],
   "source": [
    "# Convert the sparse TF-IDF matrix to a dense array\n",
    "tfidf_sample = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Display the first 5 rows and first 10 columns of the TF-IDF matrix\n",
    "print(tfidf_sample.iloc[:5, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above displays a small portion of the matrix, showing how the first 5 Tweets relate to the first 10 words in the vocabulary. The values represent the TF-IDF scores for each word in each Tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Binary Classification\n",
    "\n",
    "Converted the sentiment labels into a binary classification problem (positive vs. negative). Trained binary classifiers models like Logistic Regression, Random Forest and SVM using the TF-IDF features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a. Tuned Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy after Tuning: 0.8774647887323944\n",
      "Classification Report after Tuning:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.61      0.61       114\n",
      "    Positive       0.92      0.93      0.93       596\n",
      "\n",
      "    accuracy                           0.88       710\n",
      "   macro avg       0.77      0.77      0.77       710\n",
      "weighted avg       0.88      0.88      0.88       710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Convert sentiment labels into a binary classification task (positive vs. negative)\n",
    "# Exclude 'No emotion' and 'I can't tell' classes for this binary task\n",
    "binary_data = cleaned_tweet_data[cleaned_tweet_data['is_there_an_emotion_directed_at_a_brand_or_product'].isin(['Positive emotion', 'Negative emotion'])]\n",
    "\n",
    "# Re-apply the TF-IDF transformation on the filtered data\n",
    "X_tfidf_binary = tfidf_vectorizer.transform(binary_data['cleaned_text'])\n",
    "\n",
    "# Prepare target variable (1 for positive, 0 for negative)\n",
    "y_binary = binary_data['is_there_an_emotion_directed_at_a_brand_or_product'].apply(lambda x: 1 if x == 'Positive emotion' else 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_binary, y_binary, test_size=0.2, random_state=42, stratify=y_binary)\n",
    "\n",
    "# Apply SMOTE to the training data to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l2'],  # Penalty norm (L1 norm is typically supported with 'liblinear' or 'saga')\n",
    "    'solver': ['liblinear', 'saga']  # Solvers compatible with penalty\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "\n",
    "# Set up GridSearchCV with 3-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the SMOTE-balanced training data\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Display the best hyperparameters found\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Train the best model found by GridSearchCV\n",
    "best_logreg = grid_search.best_estimator_\n",
    "y_pred_best = best_logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_best)\n",
    "report_tuned = classification_report(y_test, y_pred_best, target_names=['Negative', 'Positive'])\n",
    "\n",
    "# Display the evaluation scores\n",
    "print(f\"Accuracy after Tuning: {accuracy_tuned}\")\n",
    "print(\"Classification Report after Tuning:\\n\", report_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for the binary classification task with a tuned logistic regression model:\n",
    "\n",
    "* **Accuracy:** 88%\n",
    "\n",
    "* **Negative Class (Precision: 0.62, Recall: 0.61, F1-score: 0.61):** The model performs moderately well at identifying negative sentiment, with a precision of 0.62 and recall of 0.61. This indicates that while the model captures 61% of actual negative tweets, it also has some false positives, meaning it is not fully confident in its negative predictions. The F1-score of 0.61 shows a reasonable balance between precision and recall, but there is room for improvement in recall to better identify more negative cases.\n",
    "\n",
    "* **Positive Class (Precision: 0.92, Recall: 0.93, F1-score: 0.93):** The model performs excellently with positive sentiment, achieving high precision (0.92) and recall (0.93). This shows that the model is very good at both identifying and classifying positive tweets, with very few false positives and missed positive cases. The high F1-score of 0.93 reflects the model's strength in consistently capturing positive sentiment accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b. Tuned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy after Tuning: 0.8873239436619719\n",
      "Classification Report after Tuning:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.38      0.52       114\n",
      "    Positive       0.89      0.98      0.94       596\n",
      "\n",
      "    accuracy                           0.89       710\n",
      "   macro avg       0.86      0.68      0.73       710\n",
      "weighted avg       0.88      0.89      0.87       710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt']   # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Set up GridSearchCV with 3-fold cross-validation\n",
    "grid_search_rf = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the SMOTE-balanced training data\n",
    "grid_search_rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Display the best hyperparameters found\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(f\"Best Parameters: {best_params_rf}\")\n",
    "\n",
    "# Train the best model found by GridSearchCV\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "accuracy_tuned_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "report_tuned_rf = classification_report(y_test, y_pred_best_rf, target_names=['Negative', 'Positive'])\n",
    "\n",
    "# Display the evaluation scores\n",
    "print(f\"Accuracy after Tuning: {accuracy_tuned_rf}\")\n",
    "print(\"Classification Report after Tuning:\\n\", report_tuned_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for the binary classification task with tuned Random Forest model:\n",
    "\n",
    "* **Accuracy:** 89%\n",
    "\n",
    "* **Negative Class (Precision: 0.83, Recall: 0.38, F1-Score: 0.52):** The random forest model has a high precision of 0.83 for the negative class, meaning that when it predicts negative sentiment, it is correct 83% of the time. However, its recall is low at 0.38, meaning it only captures 38% of the actual negative cases. This indicates that the model misses a significant portion of negative sentiment. The overall F1-score is 0.52, reflecting the trade-off between precision and recall.\n",
    "\n",
    "* **Positive Class (Precision: 0.89, Recall: 0.98, F1-Score: 0.94):** The model performs very well on the positive class with high precision (0.89) and recall (0.98), meaning it captures almost all positive cases while maintaining a high level of confidence in its predictions. The F1-score of 0.94 shows excellent performance in predicting positive sentiment. performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c. Tuned SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best Parameters for SVM: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "Accuracy after SVM Tuning: 0.8845070422535212\n",
      "Classification Report after SVM Tuning:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.34      0.49       114\n",
      "    Positive       0.89      0.99      0.93       596\n",
      "\n",
      "    accuracy                           0.88       710\n",
      "   macro avg       0.87      0.67      0.71       710\n",
      "weighted avg       0.88      0.88      0.86       710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],  # Linear or RBF kernel\n",
    "    'gamma': [0.01, 0.1, 1, 10]  # Kernel coefficient for non-linear kernels\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Set up GridSearchCV with cross-validation\n",
    "grid_search_svm = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV to the SMOTE-balanced training data\n",
    "grid_search_svm.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Display the best hyperparameters found\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "print(f\"Best Parameters for SVM: {best_params_svm}\")\n",
    "\n",
    "# Train the best model found by GridSearchCV\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "y_pred_best_svm = best_svm.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned SVM model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_best_svm)\n",
    "report_svm = classification_report(y_test, y_pred_best_svm, target_names=['Negative', 'Positive'])\n",
    "\n",
    "# Display the evaluation scores\n",
    "print(f\"Accuracy after SVM Tuning: {accuracy_svm}\")\n",
    "print(\"Classification Report after SVM Tuning:\\n\", report_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for the binary classification task with tuned SVM model:\n",
    "\n",
    "* **Accuracy:** 88%\n",
    "\n",
    "* **Negative Class (Precision: 0.85, Recall: 0.34, F1-Score: 0.49):** The model performs very well in terms of precision for the negative class, meaning that when the model predicts negative sentiment, it is correct 85% of the time. This reflects the model’s confidence in correctly identifying negative sentiment when it makes a negative prediction. The recall of 0.34 indicates that the model only captures 34% of actual negative cases, meaning it misses a large portion of negative tweets. This shows that the SVM is struggling to recall negative cases. The F1-score for the negative class, which balances precision and recall, is 0.49, reflecting that the model’s performance for the negative class is heavily weighted toward precision but lacks recall, resulting in a lower overall balance.\n",
    "\n",
    "* **Positive Class (Precision: 0.89, Recall: 0.99, F1-Score: 0.93):** The model performs very well with positive sentiment, achieving 89% precision, meaning that when the model predicts positive sentiment, it is correct most of the time. The recall for the positive class is extremely high at 0.99, meaning that the model correctly identifies 99% of all positive tweets, missing very few positive cases. The F1-score for the positive class is 0.93, reflecting an excellent balance between precision and recall for positive sentiment predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Classification Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned random forest model is likely the best fit for a generalized sentiment analysis approach.\n",
    "\n",
    "While the tuned logistic regression model provides better balance for the negative class, the overall performance of random forest aligns better with the business objective of identifying generalized sentiment trends across social media.\n",
    "\n",
    "The random forest model is consistent and performs very well for the positive class, with strong precision and recall. Even though its recall for the negative class is lower, its overall accuracy (89%) and performance for positive sentiment—which is likely to be the dominant class in a generalized sentiment analysis—makes it the most robust option for broad trend analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
