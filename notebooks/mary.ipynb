{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Machine Learnings Libraries\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading dataset\n",
    "df = pd.read_csv('../data_file/tweet_sentiments.csv', encoding='ISO-8859-1')\n",
    "\n",
    "#Display The first five columns of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of the  dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of our dataset, (9093, 3), which indicates that we have 9,093 rows and 3 columns. Here's a breakdown of what each dimension typically represents in this context:\n",
    "\n",
    "Rows (9093): This is the number of tweets in our dataset, meaning we have 9,093 individual tweets to analyze.\n",
    "\n",
    "Columns (3): This likely represents:\n",
    "\n",
    "**tweet_text:** The text content of the tweet.\n",
    "\n",
    "**emotion_in_tweet_is_directed_at:** The specific brand or product that the emotion in the tweet is directed towards.\n",
    "\n",
    "**is_there_an_emotion_directed_at_a_brand_or_product:** The sentiment or emotion expressed in relation to the brand or product (e.g., positive or negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                              tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...   \n",
       "9090  Google's Zeiger, a physician never reported po...   \n",
       "9091  Some Verizon iPhone customers complained their...   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "9088                            iPad   \n",
       "9089                             NaN   \n",
       "9090                             NaN   \n",
       "9091                             NaN   \n",
       "9092                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "9088                                   Positive emotion  \n",
       "9089                 No emotion toward brand or product  \n",
       "9090                 No emotion toward brand or product  \n",
       "9091                 No emotion toward brand or product  \n",
       "9092                 No emotion toward brand or product  \n",
       "\n",
       "[9093 rows x 3 columns]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                               1\n",
       "emotion_in_tweet_is_directed_at                       5802\n",
       "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any missing values \n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing tweet text:\n",
      "  tweet_text emotion_in_tweet_is_directed_at  \\\n",
      "6        NaN                             NaN   \n",
      "\n",
      "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
      "6                 No emotion toward brand or product  \n",
      "Number of missing emotions directed at a brand or product: 5802\n",
      "Distribution of sentiment toward brand or product:\n",
      "No emotion toward brand or product    5389\n",
      "Positive emotion                      2978\n",
      "Negative emotion                       570\n",
      "I can't tell                           156\n",
      "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64\n",
      "Cleaned DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9092 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 284.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check which entry is missing in tweet_text\n",
    "missing_tweet = df[df['tweet_text'].isnull()]\n",
    "print(\"Missing tweet text:\")\n",
    "print(missing_tweet)\n",
    "\n",
    "# Analyze the distribution of emotions directed at brands/products\n",
    "emotion_counts = df['emotion_in_tweet_is_directed_at'].isnull().sum()\n",
    "print(f\"Number of missing emotions directed at a brand or product: {emotion_counts}\")\n",
    "\n",
    "# Check the distribution of values in the sentiment column\n",
    "sentiment_counts = df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()\n",
    "print(\"Distribution of sentiment toward brand or product:\")\n",
    "print(sentiment_counts)\n",
    "\n",
    "# Clean data by dropping rows with missing tweet_text if necessary\n",
    "df_cleaned = df.dropna(subset=['tweet_text'])\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df_cleaned.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Sentiment Toward Brand or Product (is_there_an_emotion_directed_at_a_brand_or_product)**\n",
    "\n",
    "The distribution is:\n",
    "\n",
    "5389 entries show no emotion toward a brand or product.\n",
    "\n",
    "2978 entries show positive emotion.\n",
    "\n",
    "570 entries show negative emotion.\n",
    "\n",
    "156 entries have the value \"I can't tell.\n",
    "\n",
    "**Missing Tweet Text**\n",
    "\n",
    "The cleaned dataset now has 9092 rows, with no missing entries in the tweet_text column. This means that our original dataset contained 9093 rows, but after removing the rows with missing tweet_text, we were left with 9092 rows. This is a small reduction in the number of rows, but it is a necessary step to ensure that we have a complete dataset for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Preprocessing**\n",
    "\n",
    "To prepare the tweet text for analysis, we'll remove unnecessary elements such as punctuation, stopwords, and special characters. We'll also convert all text to lowercase and perform tokenization. This step will make the text suitable for feeding into a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>g iphone hrs tweeting riseaustin dead need upg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>know awesome ipadiphone app youll likely appre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>wait ipad also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>hope years festival isnt crashy years iphone a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>great stuff fri sxsw marissa mayer google tim ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  g iphone hrs tweeting riseaustin dead need upg...  \n",
       "1  know awesome ipadiphone app youll likely appre...  \n",
       "2                           wait ipad also sale sxsw  \n",
       "3  hope years festival isnt crashy years iphone a...  \n",
       "4  great stuff fri sxsw marissa mayer google tim ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column\n",
    "df_cleaned['processed_text'] = df_cleaned['tweet_text'].apply(preprocess_text)\n",
    "\n",
    "# Display the cleaned text data\n",
    "df_cleaned[['tweet_text', 'processed_text']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning and Removing Punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_punctuation = string.punctuation\n",
    "punctuation_list = english_punctuation\n",
    "def cleaning_punctuation(text):\n",
    "  translator = str.maketrans('', '', punctuation_list)\n",
    "  return text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    wesley83 I have a 3G iPhone After 3 hrs tweeti...\n",
       "1    jessedee Know about fludapp  Awesome iPadiPhon...\n",
       "2    swonderlin Can not wait for iPad 2 also They s...\n",
       "3    sxsw I hope this years festival isnt as crashy...\n",
       "4    sxtxstate great stuff on Fri SXSW Marissa Maye...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned['tweet_text'] = df_cleaned['tweet_text'].apply(lambda x: cleaning_punctuation(x))\n",
    "df_cleaned[\"tweet_text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Numeric Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    wesley I have a G iPhone After  hrs tweeting a...\n",
       "1    jessedee Know about fludapp  Awesome iPadiPhon...\n",
       "2    swonderlin Can not wait for iPad  also They sh...\n",
       "3    sxsw I hope this years festival isnt as crashy...\n",
       "4    sxtxstate great stuff on Fri SXSW Marissa Maye...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_numbers(text):\n",
    "  return re.sub('[0-9]+', '', text)\n",
    "df_cleaned['tweet_text'] = df_cleaned['tweet_text'].apply(lambda x: cleaning_numbers(x))\n",
    "df_cleaned[\"tweet_text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Tokenization Of Tweet Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [wesley, I, have, a, G, iPhone, After, hrs, tw...\n",
       "1    [jessedee, Know, about, fludapp, Awesome, iPad...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') # this match one or more words, digits, underscores\n",
    "df_cleaned['tweet_text'] = df_cleaned['tweet_text'].apply(tokenizer.tokenize)\n",
    "df_cleaned['tweet_text'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applyig Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [wesley, I, have, a, G, iphon, after, hr, twee...\n",
       "1    [jessede, know, about, fludapp, awesom, ipadip...\n",
       "2    [swonderlin, can, not, wait, for, ipad, also, ...\n",
       "3    [sxsw, I, hope, thi, year, festiv, isnt, as, c...\n",
       "4    [sxtxstate, great, stuff, on, fri, sxsw, maris...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = nltk.PorterStemmer()\n",
    "\n",
    "def stemming_on_text(data):\n",
    "  text = [st.stem(word) for word in data]\n",
    "  return text\n",
    "df_cleaned['tweet_text'] = df_cleaned['tweet_text'].apply(lambda x: stemming_on_text(x))\n",
    "df_cleaned['tweet_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Lemmatization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
